{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urlparse, urljoin\n",
    "import concurrent.futures\n",
    "import sys\n",
    "import pandas as pd\n",
    "import json\n",
    "import queue\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_web(start, success_file_path, error_file_path):\n",
    "    unseen = set([start])\n",
    "    seen = set([])\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        while unseen:\n",
    "            url = unseen.pop()\n",
    "            seen.add(url)\n",
    "            executor.submit(crawl_website, url, seen, unseen, success_file_path, error_file_path)\n",
    "\n",
    "    print(f\"Finished crawling {start}\")\n",
    "    return seen \n",
    "\n",
    "def crawl_website(url, seen, unseen, success_file_path, error_file_path):\n",
    "    try:\n",
    "        new_links = getNewLinks(url, seen, unseen, success_file_path)\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "            for link in new_links:\n",
    "                print(f\"Adding: {link}\")\n",
    "                unseen.add(link)  \n",
    "                executor.submit(crawl_website, link, seen, unseen, success_file_path, error_file_path)\n",
    "    except:\n",
    "        print(f\"Error crawling {url}\")\n",
    "        with open(error_file_path, 'a') as f:\n",
    "            f.write(f\"{url}\\n\")\n",
    "\n",
    "def save_links_to_file(links, file_path):\n",
    "    with open(file_path, 'a') as f:\n",
    "        for link in links:\n",
    "            if not is_duplicate_link(link, file_path):\n",
    "                f.write(f\"{link}\\n\")\n",
    "                \n",
    "def getNewLinks(url, seen, unseen, success_file_path):\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        links = [link['href'] for link in soup.find_all('a') if link.has_attr('href') and not any(ext in link['href'] for ext in ['.png', '.pdf', '.jpg', '.jpeg', '~json/', 'javascript:;', 'mailto:', 'webcal:'])]\n",
    "        links = [urljoin(url, link) for link in links]\n",
    "        links = [link for link in links if link not in seen and link not in unseen and urlparse(link).netloc.endswith('studentaffairs.jhu.edu')] # Change this to limit domain\n",
    "        save_links_to_file(links, success_file_path)\n",
    "        return links\n",
    "    return []\n",
    "\n",
    "def is_duplicate_link(link, file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            if link.strip() == line.strip():\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def domain(url1, url2):\n",
    "    return urlparse(url1).netloc == urlparse(url2).netloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crawled_links = crawl_web('https://studentaffairs.jhu.edu', \"links.txt\", \"error.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ds/33bb8_h50z75_0klrf43_bqm0000gn/T/ipykernel_16782/3565076695.py:2: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(\"../data/studentaffairs-jhu-edu/links.txt\", header=None, error_bad_lines=False)\n",
      "b'Skipping line 3123: expected 1 fields, saw 2\\nSkipping line 8375: expected 1 fields, saw 2\\n'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://studentaffairs.jhu.edu/orientation/new...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://studentaffairs.jhu.edu/orientation/new...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://studentaffairs.jhu.edu/student-success...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://studentaffairs.jhu.edu/student-success...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://studentaffairs.jhu.edu/leed#content</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11775</th>\n",
       "      <td>https://studentaffairs.jhu.edu/fellowships/201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11776</th>\n",
       "      <td>https://studentaffairs.jhu.edu/fellowships/tag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11777</th>\n",
       "      <td>https://studentaffairs.jhu.edu/fellowships/tag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11780</th>\n",
       "      <td>https://studentaffairs.jhu.edu/fellowships/cat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11781</th>\n",
       "      <td>https://studentaffairs.jhu.edu/fellowships/cat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9404 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Link\n",
       "0      https://studentaffairs.jhu.edu/orientation/new...\n",
       "1      https://studentaffairs.jhu.edu/orientation/new...\n",
       "2      https://studentaffairs.jhu.edu/student-success...\n",
       "3      https://studentaffairs.jhu.edu/student-success...\n",
       "4            https://studentaffairs.jhu.edu/leed#content\n",
       "...                                                  ...\n",
       "11775  https://studentaffairs.jhu.edu/fellowships/201...\n",
       "11776  https://studentaffairs.jhu.edu/fellowships/tag...\n",
       "11777  https://studentaffairs.jhu.edu/fellowships/tag...\n",
       "11780  https://studentaffairs.jhu.edu/fellowships/cat...\n",
       "11781  https://studentaffairs.jhu.edu/fellowships/cat...\n",
       "\n",
       "[9404 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load crawled links from file into a dataframe (in case of termination)\n",
    "df = pd.read_csv(\"../data/studentaffairs-jhu-edu/links.txt\", header=None, error_bad_lines=False)\n",
    "\n",
    "# Rename column\n",
    "df.rename(columns={0: \"Link\"}, inplace=True)\n",
    "\n",
    "# Normalize dataframe (remove any links that are not jhu.edu in base url or no https:// in the link)\n",
    "df = df[df['Link'].str.contains(\"https://studentaffairs.jhu.edu\")]\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Remove leading/trailing whitespace, condense multiple whitespaces to single\n",
    "    return ' '.join(text.split())\n",
    "\n",
    "def scrape_page(url, q):\n",
    "    res = requests.get(url)\n",
    "    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "\n",
    "    tags = ['p', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'span', 'li', 'div', 'table', 'th', 'td', 'tr', 'ol', 'ul', 'blockquote', 'pre', 'code', 'caption', 'dt', 'dd']\n",
    "\n",
    "    text_data = []\n",
    "    for tag in tags:\n",
    "        elements = soup.find_all(tag)\n",
    "        for element in elements:\n",
    "            text = clean_text(element.get_text())\n",
    "            if text:\n",
    "                text_data.append(text)\n",
    "\n",
    "    json_data = []\n",
    "    for i in range(len(text_data) - 1):\n",
    "        json_data.append({\n",
    "            'prompt': text_data[i],\n",
    "            'completion': text_data[i + 1]\n",
    "        })\n",
    "        \n",
    "    # add to queue\n",
    "    q.put(json_data)\n",
    "    \n",
    "def write_to_file(q):\n",
    "    with open('../data/studentaffairs-jhu-edu/data.json', 'a') as f:\n",
    "        while True:\n",
    "            data = q.get()\n",
    "            if data is None:\n",
    "                break\n",
    "            json.dump(data, f)\n",
    "            f.write('\\n')\n",
    "            q.task_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of URLs to scrape\n",
    "urls = df['Link'].tolist()\n",
    "\n",
    "# create a queue\n",
    "q = queue.Queue()\n",
    "\n",
    "# create a separate thread to write data to file\n",
    "file_writer = threading.Thread(target=write_to_file, args=(q,))\n",
    "file_writer.start()\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    futures = {executor.submit(scrape_page, url, q) for url in urls}\n",
    "    concurrent.futures.wait(futures)\n",
    "\n",
    "# stop the file writing thread\n",
    "q.put(None)\n",
    "file_writer.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Prompt/Completion pairs before cleaning: 2258820\n",
      "Number of Prompt/Completion pairs after cleaning: 48863\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>completion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99901</th>\n",
       "      <td>Dr. Charles Lu currently serves as the Associa...</td>\n",
       "      <td>Dr. Lu has been a clinical professor, teaching...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99902</th>\n",
       "      <td>Dr. Lu has been a clinical professor, teaching...</td>\n",
       "      <td>Committed to how research and scholarship conn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99903</th>\n",
       "      <td>Committed to how research and scholarship conn...</td>\n",
       "      <td>Over the years, Dr. Lu has served as an educat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99904</th>\n",
       "      <td>Over the years, Dr. Lu has served as an educat...</td>\n",
       "      <td>© Johns Hopkins UniversityBaltimore, Maryland ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99917</th>\n",
       "      <td>Office of the Dean of Student Life &gt; Center fo...</td>\n",
       "      <td>Office of the Dean of Student Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2258814</th>\n",
       "      <td>Choosing majors and courses Covering the costs...</td>\n",
       "      <td>Current Season 2023-2024 Season Auditions Conc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2258815</th>\n",
       "      <td>Current Season 2023-2024 Season Auditions Conc...</td>\n",
       "      <td>2023-2024 Season Auditions Concerto Competitio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2258816</th>\n",
       "      <td>2023-2024 Season Auditions Concerto Competitio...</td>\n",
       "      <td>Mission &amp; Advisory Board Staff &amp; Musicians Ens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2258818</th>\n",
       "      <td>Donate Volunteer</td>\n",
       "      <td>Mission &amp; Advisory Board Staff &amp; Musicians Ens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2258819</th>\n",
       "      <td>Mission &amp; Advisory Board Staff &amp; Musicians Ens...</td>\n",
       "      <td>Orchestra Policies Full Season Schedule Detail...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48863 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    prompt  \\\n",
       "99901    Dr. Charles Lu currently serves as the Associa...   \n",
       "99902    Dr. Lu has been a clinical professor, teaching...   \n",
       "99903    Committed to how research and scholarship conn...   \n",
       "99904    Over the years, Dr. Lu has served as an educat...   \n",
       "99917    Office of the Dean of Student Life > Center fo...   \n",
       "...                                                    ...   \n",
       "2258814  Choosing majors and courses Covering the costs...   \n",
       "2258815  Current Season 2023-2024 Season Auditions Conc...   \n",
       "2258816  2023-2024 Season Auditions Concerto Competitio...   \n",
       "2258818                                   Donate Volunteer   \n",
       "2258819  Mission & Advisory Board Staff & Musicians Ens...   \n",
       "\n",
       "                                                completion  \n",
       "99901    Dr. Lu has been a clinical professor, teaching...  \n",
       "99902    Committed to how research and scholarship conn...  \n",
       "99903    Over the years, Dr. Lu has served as an educat...  \n",
       "99904    © Johns Hopkins UniversityBaltimore, Maryland ...  \n",
       "99917                   Office of the Dean of Student Life  \n",
       "...                                                    ...  \n",
       "2258814  Current Season 2023-2024 Season Auditions Conc...  \n",
       "2258815  2023-2024 Season Auditions Concerto Competitio...  \n",
       "2258816  Mission & Advisory Board Staff & Musicians Ens...  \n",
       "2258818  Mission & Advisory Board Staff & Musicians Ens...  \n",
       "2258819  Orchestra Policies Full Season Schedule Detail...  \n",
       "\n",
       "[48863 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pairs into a dataframe\n",
    "with open('../data/studentaffairs-jhu-edu/data.json', 'r') as f:\n",
    "    data = []\n",
    "    for line in f:\n",
    "        # Error handling\n",
    "        try:\n",
    "            data.extend(json.loads(line))\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "pc_pairs_df = pd.DataFrame(data)\n",
    "\n",
    "print(f\"Number of Prompt/Completion pairs before cleaning: {len(pc_pairs_df)}\")\n",
    "\n",
    "# Remove any prompts/completion pairs that contains characters less than 15\n",
    "pc_pairs_df = pc_pairs_df[pc_pairs_df['prompt'].str.len() > 15]\n",
    "pc_pairs_df = pc_pairs_df[pc_pairs_df['completion'].str.len() > 15]\n",
    "\n",
    "# # Remove any prompts/completion pairs that are more than 1024 characters\n",
    "# pc_pairs_df = pc_pairs_df[pc_pairs_df['prompt'].str.len() < 1024]\n",
    "# pc_pairs_df = pc_pairs_df[pc_pairs_df['completion'].str.len() < 1024]\n",
    "\n",
    "# Remove duplicates\n",
    "pc_pairs_df.drop_duplicates(subset='prompt', keep='last', inplace=True)\n",
    "\n",
    "# Save to JSON file in the format of {\"prompt\": \"prompt text\", \"completion\": \"completion text\"}\n",
    "pc_pairs_df.to_json('../data/studentaffairs-jhu-edu/prompt-completion-pairs.json', orient='records', lines=True)\n",
    "\n",
    "print(f\"Number of Prompt/Completion pairs after cleaning: {len(pc_pairs_df)}\")\n",
    "\n",
    "pc_pairs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of links: 9404\n",
      "Number of words in dataset: 1095624\n",
      "Number of Prompt/Completion pairs after cleaning: 35426\n"
     ]
    }
   ],
   "source": [
    "# Get dataset statistics\n",
    "# Amount of links (from links.txt)\n",
    "print(f\"Number of links: {len(df)}\")\n",
    "\n",
    "# Amount of words in dataset\n",
    "print(f\"Number of words in dataset: {pc_pairs_df['prompt'].apply(lambda x: len(x.split())).sum()}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
