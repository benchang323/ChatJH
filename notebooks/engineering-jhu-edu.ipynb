{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "# Import Dependencies\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urlparse, urljoin\n",
    "import concurrent.futures\n",
    "import sys\n",
    "import pandas as pd\n",
    "import json\n",
    "import queue\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_web(start, success_file_path, error_file_path):\n",
    "    unseen = set([start])\n",
    "    seen = set([])\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=6) as executor:\n",
    "        while unseen:\n",
    "            url = unseen.pop()\n",
    "            seen.add(url)\n",
    "            executor.submit(crawl_website, url, seen, unseen, success_file_path, error_file_path)\n",
    "\n",
    "    print(f\"Finished crawling {start}\")\n",
    "    return seen \n",
    "\n",
    "def crawl_website(url, seen, unseen, success_file_path, error_file_path):\n",
    "    try:\n",
    "        new_links = getNewLinks(url, seen, unseen, success_file_path)\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=6) as executor:\n",
    "            for link in new_links:\n",
    "                print(f\"Adding: {link}\")\n",
    "                unseen.add(link)  \n",
    "                executor.submit(crawl_website, link, seen, unseen, success_file_path, error_file_path)\n",
    "    except:\n",
    "        print(f\"Error crawling {url} due to {sys.exc_info()[0]}\")\n",
    "        with open(error_file_path, 'a') as f:\n",
    "            f.write(f\"{url}\\n\")\n",
    "\n",
    "def save_links_to_file(links, file_path):\n",
    "    with open(file_path, 'a') as f:\n",
    "        for link in links:\n",
    "            if not is_duplicate_link(link, file_path):\n",
    "                f.write(f\"{link}\\n\")\n",
    "                \n",
    "def getNewLinks(url, seen, unseen, success_file_path):\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        links = [link['href'] for link in soup.find_all('a') if link.has_attr('href') and not any(ext in link['href'] for ext in ['.png', '.pdf', '.jpg', '.jpeg', '~json/', 'javascript:;', 'mailto:', 'webcal:', 'email-protection'])]\n",
    "        links = [urljoin(url, link) for link in links]\n",
    "        links = [link for link in links if link not in seen and link not in unseen and urlparse(link).netloc.endswith('engineering.jhu.edu')] # Change this to limit domain\n",
    "        save_links_to_file(links, success_file_path)\n",
    "        return links\n",
    "    else:\n",
    "        print(f\"Error getting {url} with status code {response.status_code} and reason {response.reason}\")\n",
    "        print(f\"Error full response: {response.text}\")\n",
    "    return []\n",
    "\n",
    "def is_duplicate_link(link, file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            if link.strip() == line.strip():\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def domain(url1, url2):\n",
    "    return urlparse(url1).netloc == urlparse(url2).netloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crawled_links = crawl_web('https://engineering.jhu.edu/', \"../backend/data/engineering-jhu-edu/success_links.txt\", \"../backend/data/engineering-jhu-edu/error_links.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ds/33bb8_h50z75_0klrf43_bqm0000gn/T/ipykernel_26289/2917520539.py:2: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv(\"../backend/data.nosync/engineering-jhu-edu/success_links.txt\", header=None, error_bad_lines=False)\n",
      "Skipping line 8932: expected 1 fields, saw 2\n",
      "Skipping line 8951: expected 1 fields, saw 3\n",
      "Skipping line 8973: expected 1 fields, saw 2\n",
      "Skipping line 9907: expected 1 fields, saw 2\n",
      "Skipping line 9926: expected 1 fields, saw 3\n",
      "Skipping line 9948: expected 1 fields, saw 2\n",
      "Skipping line 10388: expected 1 fields, saw 2\n",
      "Skipping line 10407: expected 1 fields, saw 3\n",
      "Skipping line 10429: expected 1 fields, saw 2\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>https://engineering.jhu.edu/#skip_content</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>https://engineering.jhu.edu/#alert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>https://engineering.jhu.edu/about/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>https://engineering.jhu.edu/resource-finder/?q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>https://engineering.jhu.edu/faculty/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10594</th>\n",
       "      <td>https://engineering.jhu.edu/csms/csms/papers/A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10595</th>\n",
       "      <td>https://engineering.jhu.edu/csms/csms/papers/G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10596</th>\n",
       "      <td>https://engineering.jhu.edu/csms/csms/papers/V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10597</th>\n",
       "      <td>https://engineering.jhu.edu/csms/csms/papers/V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10598</th>\n",
       "      <td>https://engineering.jhu.edu/outreach/category/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10181 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Link\n",
       "27             https://engineering.jhu.edu/#skip_content\n",
       "28                    https://engineering.jhu.edu/#alert\n",
       "29                    https://engineering.jhu.edu/about/\n",
       "30     https://engineering.jhu.edu/resource-finder/?q...\n",
       "31                  https://engineering.jhu.edu/faculty/\n",
       "...                                                  ...\n",
       "10594  https://engineering.jhu.edu/csms/csms/papers/A...\n",
       "10595  https://engineering.jhu.edu/csms/csms/papers/G...\n",
       "10596  https://engineering.jhu.edu/csms/csms/papers/V...\n",
       "10597  https://engineering.jhu.edu/csms/csms/papers/V...\n",
       "10598  https://engineering.jhu.edu/outreach/category/...\n",
       "\n",
       "[10181 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load crawled links from file into a dataframe (in case of termination)\n",
    "df = pd.read_csv(\"../backend/data.nosync/engineering-jhu-edu/success_links.txt\", header=None, error_bad_lines=False)\n",
    "\n",
    "# Rename column\n",
    "df.rename(columns={0: \"Link\"}, inplace=True)\n",
    "\n",
    "# Normalize dataframe (remove any links that are not jhu.edu in base url or no https:// in the link)\n",
    "df = df[df['Link'].str.contains(\"https://engineering.jhu.edu\")]\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Remove leading/trailing whitespace, condense multiple whitespaces to single\n",
    "    return ' '.join(text.split())\n",
    "\n",
    "def scrape_page(url, q):\n",
    "    res = requests.get(url)\n",
    "    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "\n",
    "    tags = ['p', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'span', 'li', 'div', 'table', 'th', 'td', 'tr', 'ol', 'ul', 'blockquote', 'pre', 'code', 'caption', 'dt', 'dd']\n",
    "\n",
    "    text_data = []\n",
    "    for tag in tags:\n",
    "        elements = soup.find_all(tag)\n",
    "        for element in elements:\n",
    "            text = clean_text(element.get_text())\n",
    "            if text:\n",
    "                text_data.append(text)\n",
    "\n",
    "    json_data = []\n",
    "    for i in range(len(text_data) - 1):\n",
    "        json_data.append({\n",
    "            'prompt': text_data[i],\n",
    "            'completion': text_data[i + 1]\n",
    "        })\n",
    "        \n",
    "    # add to queue\n",
    "    q.put(json_data)\n",
    "    \n",
    "def write_to_file(q):\n",
    "    with open('../backend/data.nosync/engineering-jhu-edu/data.json', 'a') as f:\n",
    "        while True:\n",
    "            data = q.get()\n",
    "            if data is None:\n",
    "                break\n",
    "            json.dump(data, f)\n",
    "            f.write('\\n')\n",
    "            q.task_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of URLs to scrape\n",
    "urls = df['Link'].tolist()\n",
    "\n",
    "# create a queue\n",
    "q = queue.Queue()\n",
    "\n",
    "# create a separate thread to write data to file\n",
    "file_writer = threading.Thread(target=write_to_file, args=(q,))\n",
    "file_writer.start()\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    futures = {executor.submit(scrape_page, url, q) for url in urls}\n",
    "    concurrent.futures.wait(futures)\n",
    "\n",
    "# stop the file writing thread\n",
    "q.put(None)\n",
    "file_writer.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Prompt/Completion pairs before cleaning: 3557565\n",
      "Number of words scraped (prompt): 61577293\n",
      "Number of words scraped (completion): 61404939\n",
      "Number of Prompt/Completion pairs after cleaning: 53532\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>completion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39135</th>\n",
       "      <td>Johns Hopkins Engineering press releases</td>\n",
       "      <td>Johns Hopkins Engineering press releases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39145</th>\n",
       "      <td>Johns Hopkins leads nation in research spendin...</td>\n",
       "      <td>Johns Hopkins leads nation in research spendin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39150</th>\n",
       "      <td>Johns Hopkins Title IX coordinator to depart f...</td>\n",
       "      <td>Johns Hopkins Title IX coordinator to depart f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39155</th>\n",
       "      <td>Krieger School announces new funding for inter...</td>\n",
       "      <td>Krieger School announces new funding for inter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39359</th>\n",
       "      <td>Search our experts database</td>\n",
       "      <td>Contact JHU Media Relations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3557560</th>\n",
       "      <td>About Us Curriculum &amp; Enrichment After-School ...</td>\n",
       "      <td>Activities Curriculum Research-Based Strategie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3557561</th>\n",
       "      <td>Activities Curriculum Research-Based Strategie...</td>\n",
       "      <td>Science Leadership Course</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3557562</th>\n",
       "      <td>Science Leadership Course</td>\n",
       "      <td>Latest Articles Calendar STEM Newsletter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3557563</th>\n",
       "      <td>Latest Articles Calendar STEM Newsletter</td>\n",
       "      <td>Whiting School of Engineering Johns Hopkins Un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3557564</th>\n",
       "      <td>Whiting School of Engineering Johns Hopkins Un...</td>\n",
       "      <td>Legal Privacy Statement</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53532 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    prompt  \\\n",
       "39135             Johns Hopkins Engineering press releases   \n",
       "39145    Johns Hopkins leads nation in research spendin...   \n",
       "39150    Johns Hopkins Title IX coordinator to depart f...   \n",
       "39155    Krieger School announces new funding for inter...   \n",
       "39359                          Search our experts database   \n",
       "...                                                    ...   \n",
       "3557560  About Us Curriculum & Enrichment After-School ...   \n",
       "3557561  Activities Curriculum Research-Based Strategie...   \n",
       "3557562                          Science Leadership Course   \n",
       "3557563           Latest Articles Calendar STEM Newsletter   \n",
       "3557564  Whiting School of Engineering Johns Hopkins Un...   \n",
       "\n",
       "                                                completion  \n",
       "39135             Johns Hopkins Engineering press releases  \n",
       "39145    Johns Hopkins leads nation in research spendin...  \n",
       "39150    Johns Hopkins Title IX coordinator to depart f...  \n",
       "39155    Krieger School announces new funding for inter...  \n",
       "39359                          Contact JHU Media Relations  \n",
       "...                                                    ...  \n",
       "3557560  Activities Curriculum Research-Based Strategie...  \n",
       "3557561                          Science Leadership Course  \n",
       "3557562           Latest Articles Calendar STEM Newsletter  \n",
       "3557563  Whiting School of Engineering Johns Hopkins Un...  \n",
       "3557564                            Legal Privacy Statement  \n",
       "\n",
       "[53532 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load pairs into a dataframe\n",
    "with open('../backend/data.nosync/engineering-jhu-edu/data.json', 'r') as f:\n",
    "    data = []\n",
    "    for line in f:\n",
    "        # Error handling\n",
    "        try:\n",
    "            data.extend(json.loads(line))\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "pc_pairs_df = pd.DataFrame(data)\n",
    "\n",
    "print(f\"Number of Prompt/Completion pairs before cleaning: {len(pc_pairs_df)}\")\n",
    "print(f\"Number of words scraped (prompt): {pc_pairs_df['prompt'].str.split().str.len().sum()}\")\n",
    "print(f\"Number of words scraped (completion): {pc_pairs_df['completion'].str.split().str.len().sum()}\")\n",
    "\n",
    "# Remove any prompts/completion pairs that contains characters less than 15\n",
    "pc_pairs_df = pc_pairs_df[pc_pairs_df['prompt'].str.len() > 15]\n",
    "pc_pairs_df = pc_pairs_df[pc_pairs_df['completion'].str.len() > 15]\n",
    "\n",
    "# Remove duplicates\n",
    "pc_pairs_df.drop_duplicates(subset='prompt', keep='last', inplace=True)\n",
    "\n",
    "# Save to JSON file in the format of {\"prompt\": \"prompt text\", \"completion\": \"completion text\"}\n",
    "pc_pairs_df.to_json('../backend/data.nosync/engineering-jhu-edu/prompt-completion-pairs.json', orient='records', lines=True)\n",
    "\n",
    "print(f\"Number of Prompt/Completion pairs after cleaning: {len(pc_pairs_df)}\")\n",
    "\n",
    "pc_pairs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Get dataset statistics\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# Amount of links (from links.txt)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNumber of links: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(df)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Get dataset statistics\n",
    "# Amount of links (from links.txt)\n",
    "\n",
    "# Uncomment the following line to define the df variable\n",
    "# df = pd.read_csv(\"../backend/data.nosync/engineering-jhu-edu/success_links.txt\", header=None, error_bad_lines=False)\n",
    "\n",
    "print(f\"Number of links: {len(df)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
