{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-13T17:47:59.239685Z",
     "start_time": "2023-06-13T17:47:58.919872Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "#put data into list\n",
    "data = []\n",
    "with open(\"data/studentaffairs-jhu-edu/prompt-completion-pairs.json\", 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        if len(line) < 32750:\n",
    "            data.append(json.loads(line))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-13T17:51:34.516897Z",
     "start_time": "2023-06-13T17:48:07.447580Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 to 999\n"
     ]
    },
    {
     "ename": "InvalidRequestError",
     "evalue": "'$.input' is invalid. Please check the API reference: https://platform.openai.com/docs/api-reference.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/benjamin/Desktop/Programming Repositories/Project Repositories/GPT-Project/create_embeddings.ipynb Cell 2\u001b[0m in \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/benjamin/Desktop/Programming%20Repositories/Project%20Repositories/GPT-Project/create_embeddings.ipynb#W1sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m batch \u001b[39m=\u001b[39m data[batch_start:batch_end]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/benjamin/Desktop/Programming%20Repositories/Project%20Repositories/GPT-Project/create_embeddings.ipynb#W1sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBatch \u001b[39m\u001b[39m{\u001b[39;00mbatch_start\u001b[39m}\u001b[39;00m\u001b[39m to \u001b[39m\u001b[39m{\u001b[39;00mbatch_end\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/benjamin/Desktop/Programming%20Repositories/Project%20Repositories/GPT-Project/create_embeddings.ipynb#W1sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mEmbedding\u001b[39m.\u001b[39;49mcreate(model\u001b[39m=\u001b[39;49mEMBEDDING_MODEL, \u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49mbatch)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/benjamin/Desktop/Programming%20Repositories/Project%20Repositories/GPT-Project/create_embeddings.ipynb#W1sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, be \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(response[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m]):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/benjamin/Desktop/Programming%20Repositories/Project%20Repositories/GPT-Project/create_embeddings.ipynb#W1sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39massert\u001b[39;00m i \u001b[39m==\u001b[39m be[\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m]  \u001b[39m# double check embeddings are in same order as input\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/api_resources/embedding.py:33\u001b[0m, in \u001b[0;36mEmbedding.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m         response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     35\u001b[0m         \u001b[39m# If a user specifies base64, we'll just return the encoded string.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m         \u001b[39m# This is only for the default case.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m user_provided_encoding_format:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    278\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    279\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    287\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    288\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    289\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    290\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    297\u001b[0m     )\n\u001b[0;32m--> 298\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    299\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    693\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    694\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    695\u001b[0m         )\n\u001b[1;32m    696\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    697\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    698\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 700\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    701\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    702\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    703\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    704\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    705\u001b[0m         ),\n\u001b[1;32m    706\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    707\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py:763\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    761\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    762\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 763\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    764\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    765\u001b[0m     )\n\u001b[1;32m    766\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: '$.input' is invalid. Please check the API reference: https://platform.openai.com/docs/api-reference."
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "#calculate embeddings\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
    "BATCH_SIZE = 1000\n",
    "openai.api_key = \"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\"\n",
    "embeddings = []\n",
    "for batch_start in range(0, len(data), BATCH_SIZE):\n",
    "    batch_end = batch_start + BATCH_SIZE\n",
    "    batch = data[batch_start:batch_end]\n",
    "    print(f\"Batch {batch_start} to {batch_end-1}\")\n",
    "    response = openai.Embedding.create(model=EMBEDDING_MODEL, input=batch)\n",
    "    for i, be in enumerate(response[\"data\"]):\n",
    "        assert i == be[\"index\"]  # double check embeddings are in same order as input\n",
    "    batch_embeddings = [e[\"embedding\"] for e in response[\"data\"]]\n",
    "    embeddings.extend(batch_embeddings)\n",
    "\n",
    "df = pd.DataFrame({\"text\": data, \"embedding\": embeddings})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-13T17:52:54.849673Z",
     "start_time": "2023-06-13T17:52:09.187969Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save to csv file\n",
    "SAVE_PATH = \"studentaffairs.csv\"\n",
    "\n",
    "df.to_csv(SAVE_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-13T18:28:30.296524Z",
     "start_time": "2023-06-13T18:28:29.268406Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import openai  # for calling the OpenAI API\n",
    "import pandas as pd  # for storing text and embeddings data\n",
    "import tiktoken  # for counting tokens\n",
    "from ast import literal_eval\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"unclosed\", category=ResourceWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "# models\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
    "GPT_MODEL = \"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-13T19:41:38.616005Z",
     "start_time": "2023-06-13T19:41:26.944843Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read csv file\n",
    "df = pd.read_csv(SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-13T19:57:45.205507Z",
     "start_time": "2023-06-13T19:41:54.152448Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dr. Charles Lu currently serves as the Associa...</td>\n",
       "      <td>[-0.0006251937593333423, -0.007490693591535091...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dr. Lu has been a clinical professor, teaching...</td>\n",
       "      <td>[-0.009043511003255844, -0.0004877695464529097...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Committed to how research and scholarship conn...</td>\n",
       "      <td>[-0.0037697746884077787, -0.002044877735897898...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Over the years, Dr. Lu has served as an educat...</td>\n",
       "      <td>[0.005864928010851145, -0.004018808715045452, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Office of the Dean of Student Life &gt; Center fo...</td>\n",
       "      <td>[-0.01296122744679451, -0.002553608501330018, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48723</th>\n",
       "      <td>Choosing majors and courses Covering the costs...</td>\n",
       "      <td>[0.01782906800508499, 0.003308312501758337, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48724</th>\n",
       "      <td>Current Season 2023-2024 Season Auditions Conc...</td>\n",
       "      <td>[0.010355005972087383, -0.0028163339011371136,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48725</th>\n",
       "      <td>2023-2024 Season Auditions Concerto Competitio...</td>\n",
       "      <td>[0.008355873636901379, -0.012646013870835304, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48726</th>\n",
       "      <td>Donate Volunteer Mission &amp; Advisory Board Staf...</td>\n",
       "      <td>[-0.0030530309304594994, -0.026498893275856972...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48727</th>\n",
       "      <td>Mission &amp; Advisory Board Staff &amp; Musicians Ens...</td>\n",
       "      <td>[0.0028031645342707634, -0.007798937149345875,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48728 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "0      Dr. Charles Lu currently serves as the Associa...   \n",
       "1      Dr. Lu has been a clinical professor, teaching...   \n",
       "2      Committed to how research and scholarship conn...   \n",
       "3      Over the years, Dr. Lu has served as an educat...   \n",
       "4      Office of the Dean of Student Life > Center fo...   \n",
       "...                                                  ...   \n",
       "48723  Choosing majors and courses Covering the costs...   \n",
       "48724  Current Season 2023-2024 Season Auditions Conc...   \n",
       "48725  2023-2024 Season Auditions Concerto Competitio...   \n",
       "48726  Donate Volunteer Mission & Advisory Board Staf...   \n",
       "48727  Mission & Advisory Board Staff & Musicians Ens...   \n",
       "\n",
       "                                               embedding  \n",
       "0      [-0.0006251937593333423, -0.007490693591535091...  \n",
       "1      [-0.009043511003255844, -0.0004877695464529097...  \n",
       "2      [-0.0037697746884077787, -0.002044877735897898...  \n",
       "3      [0.005864928010851145, -0.004018808715045452, ...  \n",
       "4      [-0.01296122744679451, -0.002553608501330018, ...  \n",
       "...                                                  ...  \n",
       "48723  [0.01782906800508499, 0.003308312501758337, -0...  \n",
       "48724  [0.010355005972087383, -0.0028163339011371136,...  \n",
       "48725  [0.008355873636901379, -0.012646013870835304, ...  \n",
       "48726  [-0.0030530309304594994, -0.026498893275856972...  \n",
       "48727  [0.0028031645342707634, -0.007798937149345875,...  \n",
       "\n",
       "[48728 rows x 2 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert embeddings from CSV str type back to list type\n",
    "df.head()\n",
    "df['embedding'] = df.embedding.apply(literal_eval)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-13T20:42:15.717681Z",
     "start_time": "2023-06-13T20:42:15.576110Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'clickhouse_connect'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/benjamin/Desktop/Programming Repositories/Project Repositories/GPT-Project/create_embeddings.ipynb Cell 7\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/benjamin/Desktop/Programming%20Repositories/Project%20Repositories/GPT-Project/create_embeddings.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mclickhouse_connect\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benjamin/Desktop/Programming%20Repositories/Project%20Repositories/GPT-Project/create_embeddings.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# initialize client\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benjamin/Desktop/Programming%20Repositories/Project%20Repositories/GPT-Project/create_embeddings.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m client \u001b[39m=\u001b[39m clickhouse_connect\u001b[39m.\u001b[39mget_client(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benjamin/Desktop/Programming%20Repositories/Project%20Repositories/GPT-Project/create_embeddings.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m       host\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmsc-37984436.us-east-1.aws.myscale.com\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benjamin/Desktop/Programming%20Repositories/Project%20Repositories/GPT-Project/create_embeddings.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m       port\u001b[39m=\u001b[39m\u001b[39m8443\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benjamin/Desktop/Programming%20Repositories/Project%20Repositories/GPT-Project/create_embeddings.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m       username\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlcai99\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benjamin/Desktop/Programming%20Repositories/Project%20Repositories/GPT-Project/create_embeddings.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m       password\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpasswd_GTDU9YGWNkp9VV\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benjamin/Desktop/Programming%20Repositories/Project%20Repositories/GPT-Project/create_embeddings.ipynb#W6sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m )\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'clickhouse_connect'"
     ]
    }
   ],
   "source": [
    "import clickhouse_connect\n",
    "# initialize client\n",
    "client = clickhouse_connect.get_client(\n",
    "      host='msc-37984436.us-east-1.aws.myscale.com',\n",
    "      port=8443,\n",
    "      username='lcai99',\n",
    "      password='passwd_GTDU9YGWNkp9VV'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-13T20:54:19.791777Z",
     "start_time": "2023-06-13T20:50:44.770742Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a61916eea164895bb06f246503d08a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/488 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#index data\n",
    "embedding_len=len(df['embedding'][0]) #1536\n",
    "\n",
    "client.command(f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS default.hopkins_art\n",
    "(\n",
    "    id        UInt32,\n",
    "    text      String,\n",
    "    embedding Array(Float32),\n",
    "    CONSTRAINT cons_embedding_len CHECK length(embedding) = {embedding_len},\n",
    "    VECTOR INDEX article_content_index embedding TYPE HNSWFLAT('metric_type=Cosine')\n",
    ")\n",
    "ENGINE = MergeTree ORDER BY id\n",
    "\"\"\")\n",
    "#insert data into table in batches\n",
    "from tqdm.auto import tqdm\n",
    "batch_size = 100\n",
    "total_records = len(df)\n",
    "\n",
    "data = df.to_records(index=False).tolist()\n",
    "column_names = df.columns.tolist()\n",
    "\n",
    "for i in tqdm(range(0, total_records, batch_size)):\n",
    "    i_end = min(i + batch_size, total_records)\n",
    "    client.insert(\"default.hopkins_art\", data[i:i_end], column_names=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-13T20:57:02.369574Z",
     "start_time": "2023-06-13T20:57:02.093538Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "articles count: 48728\n",
      "index build status: Built\n",
      "Built\n",
      "Built\n"
     ]
    }
   ],
   "source": [
    "# check count of inserted data\n",
    "print(f\"articles count: {client.command('SELECT count(*) FROM default.hopkins_art')}\")\n",
    "\n",
    "# check the status of the vector index, make sure vector index is ready with 'Built' status\n",
    "get_index_status=\"SELECT status FROM system.vector_indices WHERE name='article_content_index'\"\n",
    "print(f\"index build status: {client.command(get_index_status)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T00:49:55.135687Z",
     "start_time": "2023-06-14T00:49:55.131711Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def strings_ranked_by_relatedness(query: str, df: pd.DataFrame) -> list[str]:\n",
    "\n",
    "    # creates embedding vector from user query\n",
    "    embed = openai.Embedding.create(\n",
    "        input=query,\n",
    "        model=\"text-embedding-ada-002\",\n",
    "    )[\"data\"][0][\"embedding\"]\n",
    "\n",
    "    # query the database to find the top K similar content to the given query\n",
    "    top_k = 10\n",
    "    results = client.query(f\"\"\"\n",
    "    SELECT id, text, distance(embedding, {embed}) as dist\n",
    "    FROM default.hopkins_art\n",
    "    ORDER BY dist\n",
    "    LIMIT {top_k}\n",
    "    \"\"\")\n",
    "\n",
    "    # return list of most relevant results\n",
    "    return results.named_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T01:00:37.339708Z",
     "start_time": "2023-06-14T01:00:37.338629Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def num_tokens(text: str, model: str = GPT_MODEL) -> int:\n",
    "    \"\"\"Return the number of tokens in a string.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "\n",
    "def query_message(\n",
    "    query: str,\n",
    "    df: pd.DataFrame,\n",
    "    model: str,\n",
    "    token_budget: int\n",
    ") -> str:\n",
    "    \"\"\"Return a message for GPT, with relevant source texts pulled from a dataframe.\"\"\"\n",
    "    strings = strings_ranked_by_relatedness(query, df)\n",
    "    introduction = 'Use the below website information below to answer questions about the Johns Hopkins University. If the website information does not specify enough information, use previous knowledge to answer the question'\n",
    "    question = f\"\\n\\nQuestion: {query}\"\n",
    "    message = introduction\n",
    "    for string in strings:\n",
    "        next_article = f'\\n\\nJohns Hopkins article section:\\n\"\"\"\\n{string}\\n\"\"\"'\n",
    "        if (\n",
    "            num_tokens(message + next_article + question, model=model)\n",
    "            > token_budget\n",
    "        ):\n",
    "            break\n",
    "        else:\n",
    "            message += next_article\n",
    "    return message + question\n",
    "\n",
    "\n",
    "def ask(\n",
    "    query: str,\n",
    "    df: pd.DataFrame = df,\n",
    "    model: str = GPT_MODEL,\n",
    "    token_budget: int = 4096 - 500,\n",
    "    print_message: bool = False,\n",
    ") -> str:\n",
    "    \"\"\"Answers a query using GPT and a dataframe of relevant texts and embeddings.\"\"\"\n",
    "    message = query_message(query, df, model=model, token_budget=token_budget)\n",
    "    if print_message:\n",
    "        print(message)\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You answer questions about student affairs at the Johns Hopkins University\"},\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0\n",
    "    )\n",
    "    response_message = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    return response_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T01:01:20.427620Z",
     "start_time": "2023-06-14T01:01:18.473181Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ask' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/benjamin/Desktop/Programming Repositories/Project Repositories/GPT-Project/create_embeddings.ipynb Cell 12\u001b[0m in \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benjamin/Desktop/Programming%20Repositories/Project%20Repositories/GPT-Project/create_embeddings.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#example question\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/benjamin/Desktop/Programming%20Repositories/Project%20Repositories/GPT-Project/create_embeddings.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m ask(\u001b[39m\"\u001b[39m\u001b[39mWhat should I do if I have been accused of an academic integrity violation?\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ask' is not defined"
     ]
    }
   ],
   "source": [
    "#example question\n",
    "\n",
    "ask(\"What should I do if I have been accused of an academic integrity violation?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
